---
title: Deep Learning Specialization
date: 2021-02-07 18:02:57
category: coursera
draft: false

---

앤드류 응 선생님의 딥러닝 전문가 코세라 강의. 구글 부트캠프 수료 과정에서 중점적으로 들어야하는 강의이다. 2017년에 나온 강의기에 최신 트렌드를 담았다고 볼 수는 없으나 딥러닝 기초를 확립하기에 좋은 강의이다. 이미 머신러닝과 딥러닝 기초적인 내용은 개인적으로 충분하다고 오만하게 판단했지만, 첫주차 강의를 듣고 그 생각이 바뀌었다. 다른 사람들도 이 강의를 통해 확실히 딥러닝 AI 지식 기초를 다질 수 있을 것이라 확신한다.

코스는 총 5개로 구성되어 있으며, 수료하면서 요약했던 내용을 개인적인 복습 차원에서 요약 및 정리를 하려고 한다. 역전파 등 수식 과정은 이 강의 내용에서나 유튜브에서나 훨씬 더 잘 설명되어 있다고 판단되어, 이론 위주로 내용을 정리해보았다. 물론 필연적으로 수식이 등장하겠지만 깔끔하게 보여지기 위해 강의 노트를 옮겨왔다. 기본적인 annotation은 안다고 가정하였다.

Course 1. Neural Networks and Deep Learning

딥러닝을 알기 위해서는 먼저 `Logistic Regression` 을 알아야 한다. `Logistic Regression` 은 어떤 x (features) Y를 예측하는데 사용되는 기본 선형 확률 모델이다. 강의에 나왔던 예시로 예를 들자면 **어떤 사진**이 주어졌을 때 **사진이 고양이인지, 강아지인지 판단하는 작업**을 의미한다. 고양이인지, 강아지인지에 대한 분류 정확도를 로지스틱 회귀 모델은 0에서 1 사이의 확률로 표현해준다. 

이를 수식으로 간단히 정리하자면 예측값인 $\hat{y}$은 다음과 같다.
$$\hat{y} = \sigma(W^Tx + b)$$

여기서 중요한 부분은 `Sigmoid`함수 부분인데, 아래 그림은 `Sigmoid`함수를 나타낸다. 어떠한 x를 받아도 0 ~ 1 사이의 값으로 변환해주는 것을 볼 수 있다.

![logistic regression 이미지 검색결과](https://miro.medium.com/max/2400/1*RqXFpiNGwdiKBWyLJc_E7g.png)


**즉, 로지스틱 회귀 모델은 0 ~ 1 사이의 확률값으로 어떤 예측에 대한 수치를 표현하는 것이 핵심이다.** 그리
<!--stackedit_data:
eyJoaXN0b3J5IjpbMjA3MzQ0MTkxNiwtMTM3MzU4MDI1XX0=
-->